# kubernetes-yaml-file
Kubernetes  yaml files from the scratch with proper explanation easy to understand 

 # Django-Three-Tier-Manifests/ directory structure in a table format including ConfigMaps, Ingress, and PVCs:

 | Directory   | File Name         | Description                     |
| ----------- | ----------------- | ------------------------------- |
| `backend/`  | `deployment.yaml` | Backend Deployment              |
|             | `service.yaml`    | Backend Service                 |
|             | `configmap.yaml`  | Backend ConfigMap               |
|             | `pvc.yaml`        | Backend Persistent Volume Claim |
| `db/`       | `deployment.yaml` | Database Deployment             |
|             | `service.yaml`    | Database Service                |
|             | `configmap.yaml`  | DB ConfigMap                    |
|             | `pvc.yaml`        | DB Persistent Volume Claim      |
| `frontend/` | `deployment.yaml` | Frontend Deployment             |
|             | `service.yaml`    | Frontend Service                |
|             | `configmap.yaml`  | Frontend ConfigMap              |
| *(root)*    | `namespace.yaml`  | Namespace Definition            |
|             | `ingress.yaml`    | Ingress Resource                |


 # Deployments, StatefulSets, DaemonSets, etc.

| Controller Type  | Purpose                                                                                             | Typical Use Case                                                          |
| ---------------- | --------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |
| **Deployment**   | Manages stateless applications. Supports scaling, rolling updates, etc.                             | Web apps, APIs, frontends, backend services                               |
| **StatefulSet**  | Manages stateful applications. Maintains identity and storage per pod.                              | Databases (e.g., PostgreSQL, MongoDB), Kafka                              |
| **DaemonSet**    | Ensures a pod runs on **every** (or selected) node.                                                 | Node monitoring, log collection (e.g., Prometheus Node Exporter, Fluentd) |
| **Job**          | Runs a pod to completion (batch processing).                                                        | One-time tasks like backups, batch jobs                                   |
| **CronJob**      | Runs Jobs on a scheduled basis.                                                                     | Scheduled tasks like nightly DB dumps                                     |
| **ReplicaSet**\* | Ensures a specified number of pod replicas are running. *(Usually managed by Deployments directly)* | Internal use by Deployment                                                |


# apiVersion  for kinds
1. apiVersion ‚Äì API group and version used.
2. kind ‚Äì Type of Kubernetes object.
 
 
 | Kind        | apiVersion             |
| ----------- | ---------------------- |
| Deployment  | `apps/v1`              |
| Service     | `v1`                   |
| ConfigMap   | `v1`                   |
| Secret      | `v1`                   |
| Ingress     | `networking.k8s.io/v1` |
| StatefulSet | `apps/v1`              |
| Pod         | `v1`                   |



# This is Manifest 

| Resource Type         | `kind` in Manifest | Purpose                             |
| --------------------- | ------------------ | ----------------------------------- |
| Pod                   | `Pod`              | Smallest deployable unit            |
| Deployment            | `Deployment`       | Manage stateless apps               |
| Service               | `Service`          | Expose apps to the network          |
| ConfigMap             | `ConfigMap`        | Store non-confidential config       |
| Secret                | `Secret`           | Store sensitive data like passwords |
| Ingress               | `Ingress`          | HTTP(S) routing rules               |
| PersistentVolumeClaim | `PVC`              | Request storage resources           |



# üìå Key Sections in a Manifest:
# apiVersion ‚Äì API group and version used.

# kind ‚Äì Type of Kubernetes object.

# metadata ‚Äì Name, labels, annotations, etc.

# spec ‚Äì Specifications that define the object‚Äôs desired state.


‚úÖ Quick Summary:
üü¢ Horizontal Pod Autoscaler (HPA)
üëâ "Pod Replica Scaling"

Controls how many pods should run.

Increases or decreases pod replicas based on CPU, memory, or custom metrics.

üöÄ Example:
If CPU usage is high ‚Üí Add more pods.
If CPU usage is low ‚Üí Remove some pods.

üü° Vertical Pod Autoscaler (VPA)
üëâ "Pod Size Scaling"

Controls how much CPU or Memory each pod should have.

Increases or decreases resources inside the pod.

Usually restarts the pod to apply changes.

üöÄ Example:
If a pod needs more memory ‚Üí VPA increases the pod‚Äôs memory.
If a pod is using very little ‚Üí VPA can reduce the allocated CPU/memory.

üî• Super Simple:
| Feature         | HPA                | VPA                     |
| --------------- | ------------------ | ----------------------- |
| Scales          | Number of Pods     | CPU/Memory per Pod      |
| Example         | 3 Pods ‚Üí 5 Pods    | 500Mi ‚Üí 800Mi Memory    |
| Action          | More/less replicas | Bigger/smaller pod size |
| Restart Needed? | No                 | Yes (usually)           |



‚úÖ Example:
If traffic increases:
üëâ HPA adds pods to handle more requests.

If a pod needs more memory:
üëâ VPA increases the pod‚Äôs memory to avoid crashes.

#which is best HPA or  VPA

‚úÖ HPA vs VPA: Which is Best?

| Feature                    | Horizontal Pod Autoscaler (HPA)                       | Vertical Pod Autoscaler (VPA)            |
| -------------------------- | ----------------------------------------------------- | ---------------------------------------- |
| **Scaling Type**           | Number of Pods (replicas)                             | CPU/Memory per Pod                       |
| **Best For**               | Traffic spikes, load balancing                        | Unpredictable memory/CPU usage per pod   |
| **Pod Restart Needed?**    | No                                                    | Yes (to apply changes)                   |
| **Response Time**          | Fast (spins up new pods quickly)                      | Slow (needs pod restart to resize)       |
| **Typical Use Case**       | Web servers, stateless apps, APIs                     | Databases, memory-heavy apps, batch jobs |
| **Limits**                 | May hit resource limits if pods are under-provisioned | Cannot handle sudden traffic spikes      |
| **Custom Metrics Support** | Yes                                                   | No (works based on CPU/memory only)      |


‚úÖ When to Use HPA
Applications where traffic load changes quickly.

You need to scale out/in fast without restarting pods.

Example: Web servers, APIs, microservices.

‚úÖ When to Use VPA
Applications where CPU/Memory usage changes unpredictably.

Pod resource requests are hard to estimate.

Example: Databases, machine learning workloads, batch processing.

‚úÖ When to Use Both HPA + VPA
Modern Kubernetes setups often combine both for best results:

üëâ HPA handles traffic load (replica scaling).

üëâ VPA optimizes pod resource requests (so that each pod is correctly sized).

‚öôÔ∏è But:
When combining, you should:

Use HPA based on custom metrics (like QPS) instead of just CPU, to avoid conflicts.

Use VPA in 'Initial' mode (so it sets resources when pods start, but doesn‚Äôt trigger restarts).

| Scenario                                  | Best Choice |
| ----------------------------------------- | ----------- |
| Fast traffic changes (Web app)            | HPA         |
| Heavy CPU/memory load (DB, ML)            | VPA         |
| Dynamic web app with resource fluctuation | HPA + VPA   |



